{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speaker Identification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnqH4uFY0V9C",
        "colab_type": "text"
      },
      "source": [
        "# Import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVAgWzYU0L7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLLat2lz0YyB",
        "colab_type": "text"
      },
      "source": [
        "# Get the data directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX-DJBbx0b9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/Colab Notebooks/Speaker Identification/speeches_dataset.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixSGTNlp7em5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "7dfd0df4-51fa-426b-b5bf-4190a57becdc"
      },
      "source": [
        "data_dir = \"16000_pcm_speeches/\"\n",
        "os.listdir(data_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nelson_Mandela',\n",
              " 'Julia_Gillard',\n",
              " '_background_noise_',\n",
              " 'Jens_Stoltenberg',\n",
              " 'Benjamin_Netanyau',\n",
              " 'tf_Wav_reader.py',\n",
              " 'other',\n",
              " 'Magaret_Tarcher']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVG4MBb00fnd",
        "colab_type": "text"
      },
      "source": [
        "# Process training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQqaCmpr0gKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wav_paths(speaker):\n",
        "  speaker_path = data_dir + speaker\n",
        "  all_paths = [item for item in os.listdir(speaker_path)]\n",
        "  return all_paths"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyMUHqm78EJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nelson_mandela_paths = get_wav_paths(\"Nelson_Mandela\")\n",
        "margaret_thatcher_paths = get_wav_paths(\"Magaret_Tarcher\")\n",
        "benjamin_netanyau_paths = get_wav_paths(\"Benjamin_Netanyau\")\n",
        "jens_stoltenberg_paths = get_wav_paths( 'Jens_Stoltenberg')\n",
        "julia_gillard_paths = get_wav_paths(\"Julia_Gillard\")\n",
        "\n",
        "noise1_paths = get_wav_paths(\"_background_noise_\")\n",
        "noise2_paths = get_wav_paths(\"other\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qtWbuQw0lQn",
        "colab_type": "text"
      },
      "source": [
        "### load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6HNZocS0msj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_wav(wav_path, speaker):\n",
        "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
        "        wav_path = data_dir + speaker + \"/\" + wav_path\n",
        "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
        "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
        "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
        "        wav_data = sess.run(\n",
        "            wav_decoder, feed_dict={\n",
        "                wav_filename_placeholder: wav_path\n",
        "            }).audio.flatten().reshape((1, 16000))\n",
        "        sess.close()\n",
        "    return wav_data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnIxYAFk0nqa",
        "colab_type": "text"
      },
      "source": [
        "### create training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhZQY8R0qyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_training_data(speaker_paths, speaker, label):\n",
        "    wavs, labels = [], []\n",
        "    for i in tqdm(speaker_paths):\n",
        "        wav = load_wav(i, speaker)\n",
        "        wavs.append(wav)\n",
        "        labels.append(label)\n",
        "    return wavs, labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VdR8kqI-Oj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "13bdfba6-a148-4af5-dcd2-59a98a7b9052"
      },
      "source": [
        "nelson_mandela_wavs, nelson_mandela_labels = generate_training_data(nelson_mandela_paths, \"Nelson_Mandela\", 0) \n",
        "margaret_thatcher_wavs, margaret_thatcher_labels = generate_training_data(margaret_thatcher_paths, \"Magaret_Tarcher\", 1) \n",
        "benjamin_netanyau_wavs, benjamin_netanyau_labels = generate_training_data(benjamin_netanyau_paths, \"Benjamin_Netanyau\", 2) \n",
        "jens_stoltenberg_wavs, jens_stoltenberg_labels = generate_training_data(jens_stoltenberg_paths, \"Jens_Stoltenberg\", 3) \n",
        "julia_gillard_wavs, julia_gillard_labels = generate_training_data(julia_gillard_paths, \"Julia_Gillard\", 4) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1500/1500 [00:05<00:00, 264.63it/s]\n",
            "100%|██████████| 1500/1500 [00:05<00:00, 275.32it/s]\n",
            "100%|██████████| 1500/1500 [00:05<00:00, 279.13it/s]\n",
            "100%|██████████| 1500/1500 [00:05<00:00, 270.20it/s]\n",
            "100%|██████████| 1501/1501 [00:05<00:00, 273.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by2pG5ro-zI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "393aa8eb-6257-4f5d-efa3-30d42151d621"
      },
      "source": [
        "np.array(nelson_mandela_labels).shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5SaT1lz0rp_",
        "colab_type": "text"
      },
      "source": [
        "## remove the extra wav for Julia Gillard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G2z6ZAr0vj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "julia_gillard_labels = julia_gillard_labels[1:]\n",
        "julia_gillard_wavs = julia_gillard_wavs[1:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ki_5bV5_hw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "571963a7-b4c9-4c55-f6cc-9b843fb193cf"
      },
      "source": [
        "np.array(julia_gillard_labels).shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tl8_-YE_4zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_wavs = nelson_mandela_wavs + margaret_thatcher_wavs + benjamin_netanyau_wavs + jens_stoltenberg_wavs + julia_gillard_wavs\n",
        "all_labels = nelson_mandela_labels + margaret_thatcher_labels + benjamin_netanyau_labels + jens_stoltenberg_labels + julia_gillard_labels"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfQyhx2h02W0",
        "colab_type": "text"
      },
      "source": [
        "### Mixing Noise in the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZXNqEG05Ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io.wavfile import read\n",
        "from scipy.io.wavfile import write\n",
        "from random import randint\n",
        "\n",
        "def cut_random_section(noise2, size2):\n",
        "    size21 = noise2.size\n",
        "    starting_point2 = randint(0,(noise2.size - size2))\n",
        "    end_point2 = starting_point2 + size2\n",
        "    noise_cut_part2 = noise2[starting_point2:end_point2]\n",
        "    return noise_cut_part2\n",
        "\n",
        "def mix(audio1, noise1, snr1):\n",
        "    audio_max = max(audio1)\n",
        "    if audio_max==0:\n",
        "        audio_max = int(np.random.uniform(0.7,1)*32767)\n",
        "    audio1 = audio1*1.\n",
        "    audio1 = audio1/audio_max\n",
        "    noise1 = cut_random_section(noise1, audio1.size)\n",
        "    noise1 = noise1*1.\n",
        "    noise1 = noise1/max(noise1)\n",
        "    gain = pow(10,(snr1/10.))\n",
        "    numerator = np.mean(abs(audio1)**2)\n",
        "    denominator = numerator/gain\n",
        "    noise_power = np.mean(abs(noise1)**2)\n",
        "    mult_value = (denominator/noise_power)**0.5\n",
        "    noisy1 = audio1 + noise1*mult_value\n",
        "    if max(audio1)==0:\n",
        "        noisy1 = noise1\n",
        "    else:    \n",
        "        noisy1 = noisy1/max(noisy1)\n",
        "    noisy1 = np.array(noisy1*audio_max, dtype='int16')\n",
        "    return noise1*mult_value, mult_value, noisy1\n",
        "\n",
        "noise_wavs = []\n",
        "noise_labels = []\n",
        "snr_dB = 10\n",
        "for i in range(len(all_wavs)):\n",
        "    for noise in os.listdir(data_dir + 'other'):\n",
        "        fs, noise_file = read(data_dir + 'other/' + noise)\n",
        "        x = all_wavs[i][0]\n",
        "        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n",
        "        if noisy.any() != 0:\n",
        "            noise_wavs.append(noisy)\n",
        "            noise_labels.append(all_labels[i])\n",
        "    for noise in os.listdir(data_dir + '_background_noise_'):\n",
        "        fs, noise_file = read(data_dir + '_background_noise_/' + noise)\n",
        "        x = all_wavs[i][0]\n",
        "        if len(noise_file.shape) > 1:\n",
        "            noise_file = np.reshape(noise_file, (noise_file.shape[0]*noise_file.shape[1]))\n",
        "        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n",
        "        if noisy.any() != 0:\n",
        "            noise_wavs.append(noisy)\n",
        "            noise_labels.append(all_labels[i]) \n",
        "    if i%200 == 0:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LMU8mJGCi1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "582fc282-fac7-41ff-b384-6af472140d8c"
      },
      "source": [
        "for i in range(len(all_wavs)):\n",
        "  noise_labels.append(all_labels[i])\n",
        "  noise_wavs.append(all_wavs[i][0])\n",
        "final_wavs = np.array(noise_wavs)\n",
        "final_labels = np.array(noise_labels)\n",
        "\n",
        "print(final_wavs.shape,final_labels.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8161, 16000) (8161,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMBQnjFq08rV",
        "colab_type": "text"
      },
      "source": [
        "# split the dataset into trainin and testing set\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Pbnul_09YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_wavs,test_wavs,train_labels,test_labels = train_test_split(final_wavs,final_labels,test_size = 0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_8OXvQADalc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,train_y = np.array(train_wavs),np.array(train_labels)\n",
        "test_x,test_y = np.array(test_wavs),np.array(test_labels)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lNkeKYdDzyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = tf.keras.utils.to_categorical(train_y)\n",
        "test_y = tf.keras.utils.to_categorical(test_y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkeLx477Eft2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ba50f7f-7e5a-46e6-8433-7f6e013e2a45"
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7344, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuJ4MHpx0_yT",
        "colab_type": "text"
      },
      "source": [
        "# MFCC Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L5tJOsl1ATb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "1aee2850-3d7e-401f-fe81-7918663c427a"
      },
      "source": [
        "\n",
        "train_x_new = []\n",
        "test_x_new = []\n",
        "INPUT_SHAPE = (126,40)\n",
        "\n",
        "train_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
        "\n",
        "count = 0\n",
        "for sample in train_x:\n",
        "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
        "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
        "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
        "    train_x_new[count, :, :20] = mfcc.T\n",
        "    train_x_new[count, :, 20:30] = mfcc_delta.T\n",
        "    train_x_new[count, :, 30:] = mfcc_double_delta.T\n",
        "    count += 1\n",
        "    if count%500 == 0:\n",
        "        print('Train', count)\n",
        "        \n",
        "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
        "\n",
        "count = 0\n",
        "for sample in test_x:\n",
        "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
        "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
        "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
        "    test_x_new[count, :, :20] = mfcc.T\n",
        "    test_x_new[count, :, 20:30] = mfcc_delta.T\n",
        "    test_x_new[count, :, 30:] = mfcc_double_delta.T\n",
        "    count += 1\n",
        "    if count%500 == 0:\n",
        "        print('Test', count)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train 500\n",
            "Train 1000\n",
            "Train 1500\n",
            "Train 2000\n",
            "Train 2500\n",
            "Train 3000\n",
            "Train 3500\n",
            "Train 4000\n",
            "Train 4500\n",
            "Train 5000\n",
            "Train 5500\n",
            "Train 6000\n",
            "Train 6500\n",
            "Train 7000\n",
            "Test 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXShxgnF1h3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2162779-c93e-4099-bd86-15e01e26d1f3"
      },
      "source": [
        "train_x_new = np.expand_dims(train_x_new,axis = 3)\n",
        "test_x_new = np.expand_dims(test_x_new,axis = 3)\n",
        "print(train_x_new.shape,test_x_new.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7344, 126, 40, 1) (817, 126, 40, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4xb_p0U1DaV",
        "colab_type": "text"
      },
      "source": [
        "# Create a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvLmMoxD1D7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model\n",
        "def create_model(speech_feature):\n",
        "    model = tf.keras.Sequential()\n",
        "    if speech_feature == \"spectrogram\":\n",
        "        model.add(Spectrogram(n_dft=512, n_hop=256, input_shape=(1, 16000),\n",
        "                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n",
        "                            trainable_kernel=False, name='static_stft'))\n",
        "    elif speech_feature == \"melspectrogram\":\n",
        "        model.add(Melspectrogram(sr=16000, n_mels=128,n_dft=512, n_hop=256,\n",
        "                            input_shape=(1 , 16000),return_decibel_melgram=True,\n",
        "                            trainable_kernel=False, name='melgram'))\n",
        "        \n",
        "    elif speech_feature == \"mfcc\":\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", input_shape=(126,40,1)))\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "#         model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(tf.keras.layers.Flatten())        \n",
        "        model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n",
        "                , loss = \"categorical_crossentropy\"\n",
        "                , metrics = [\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n",
        "            , loss = \"categorical_crossentropy\"\n",
        "            , metrics = [\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqtoyiCt1F2R",
        "colab_type": "text"
      },
      "source": [
        "# mfcc model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK_i1LgL1GYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "3daad309-dcea-4108-a38a-eb6b4620880c"
      },
      "source": [
        "model = create_model(\"mfcc\")\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 124, 38, 128)      1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 62, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 60, 17, 64)        73792     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65280)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 326405    \n",
            "=================================================================\n",
            "Total params: 401,477\n",
            "Trainable params: 401,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTT3PeH51JKi",
        "colab_type": "text"
      },
      "source": [
        "# Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AmNUqyt1LAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "47cba51e-5618-441d-fc3f-fa40bec090ea"
      },
      "source": [
        "model.fit(x = train_x_new,y = train_y,epochs=5,validation_data=(test_x_new,test_y))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "230/230 [==============================] - 126s 548ms/step - loss: 0.1946 - accuracy: 0.9278 - val_loss: 0.2716 - val_accuracy: 0.9058\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 126s 547ms/step - loss: 0.1611 - accuracy: 0.9370 - val_loss: 0.2005 - val_accuracy: 0.9253\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 128s 557ms/step - loss: 0.1357 - accuracy: 0.9464 - val_loss: 0.2091 - val_accuracy: 0.9302\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 126s 547ms/step - loss: 0.1177 - accuracy: 0.9519 - val_loss: 0.1960 - val_accuracy: 0.9339\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 125s 545ms/step - loss: 0.1060 - accuracy: 0.9560 - val_loss: 0.2076 - val_accuracy: 0.9315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce54036a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q0u0v0_1Mcs",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOapweOq1PHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('speaker_model.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwEozD1G1PjZ",
        "colab_type": "text"
      },
      "source": [
        "# Predicting the output and analyzing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVUP59U1bLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(test_x_new)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYMhE6OpLtK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1238f8db-4c1e-44e7-fbed-d6e137e6be4a"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(817, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1hhxcqWLv4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b3d5a90-c15c-44f9-fc04-48eef488a21e"
      },
      "source": [
        "test_y.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(817, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWv_WQZpLx2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.argmax(y_pred,axis = 1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31juJUPYL6BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y = np.argmax(test_y,axis = 1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNdnhE5MFY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "f75fcc06-9412-479e-a640-52f163f8d39d"
      },
      "source": [
        "confusion_matrix(test_y,y_pred)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0],\n",
              "       [0, 2, 0, 0, 0],\n",
              "       [0, 0, 3, 0, 0],\n",
              "       [0, 0, 0, 3, 0],\n",
              "       [0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ktvvnsYMMbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}